{
  "hash": "4e181b7b00a044f8e57c22f454464b95",
  "result": {
    "markdown": "---\ntitle: \"Parallelization in R\"\nauthor: \"Temi\"\ndescription: \"How to run stuff in parallel in R\"\ndate: \"Sun Sep 3 2023\"\nformat:\n    html:\n        code-fold: true\ncategories: [how-to]\n---\n\n\n# Introduction\nWhen running computationally-heavy tasks in R, it can be useful to parallelize your codes/runs. In that vein, this is [a really good blogpost to read](https://nceas.github.io/oss-lessons/parallel-computing-in-r/parallel-computing-in-r.html) to understand when and how to parallelize. And here is [another one](https://dept.stat.lsa.umich.edu/~jerrick/courses/stat701/notes/parallel.html).\n\nR offers many ways to do this. Usually, I prefer using some libraries. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(doParallel)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: foreach\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: iterators\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: parallel\n```\n:::\n\n```{.r .cell-code}\nlibrary(foreach)\nlibrary(parallel)\n```\n:::\n\n\n## _Use case_\nAssuming we want to apply a function over the rows of a matrix. This function will take each row, divide the numbers in that row by the index of that row in the matrix and return a newly-created matrix of the same shape.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(2022)\nmyMatrix <- matrix(sample(1:50000, size=300*500, replace=T), nrow=300, ncol=500)\n\ndim(myMatrix)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 300 500\n```\n:::\n:::\n\n\n### `lapply`\nFirst, I will time this function with `lapply` loops. `lapply` is shipped with base R and is a parallel form of a regular for loop. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlapply_fxn <- function(){\n  applyMatrix <- lapply(1:nrow(myMatrix), function(i){\n    out <- myMatrix[i, ] / (i)\n    return(out)\n  })\n  applyMatrix <- do.call('rbind', applyMatrix)\n  return(applyMatrix)\n}\n\nsystem.time(lapply_fxn())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   user  system elapsed \n  0.004   0.000   0.004 \n```\n:::\n:::\n\n\n### `mclapply`\nNext, let's take advantage of the cores, this time using `mclapply`\n\n::: {.cell}\n\n```{.r .cell-code}\nmclapply_fxn <- function(){\n  applyMatrix <- parallel::mclapply(1:nrow(myMatrix), function(i){\n    out <- myMatrix[i, ] / (i)\n    return(out)\n  }, mc.cores = 12) # using 7 cores\n  \n  applyMatrix <- do.call('rbind', applyMatrix)\n  return(applyMatrix)\n}\n\nsystem.time(mclapply_fxn())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   user  system elapsed \n  0.004   0.024   0.028 \n```\n:::\n:::\n\n\nWe see that lapply is faster. This is because there is an overhead to distributing these runs and collecting their results when using `mclapply`\n\n\n### `foreach` & `%do%`\n\nHere, I will use the `foreach` but without a parallel back-end - this is akin to a sequential run, just like lapply or a regular for loop\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsystem.time({\n  outputMatrix <- foreach::foreach(i=1:nrow(myMatrix), .combine='rbind', .inorder=F) %do% {\n    out <- myMatrix[i, ] / i\n    return(out)\n  }\n})\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   user  system elapsed \n  0.035   0.008   0.043 \n```\n:::\n:::\n\n\n### `foreach` & `%dopar%`\n\nHere, I will use the `foreach` but with a parallel back-end. The parallel back-end is a cluster of cores If you are familiar with multiprocessing in python, it is equivalent to `multiprocessing.Pool`\n\nFirst we need to register a `parallel` back-end\n\nWe can query how many cores we have on this computer\n\n::: {.cell}\n\n```{.r .cell-code}\nparallel::detectCores()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 12\n```\n:::\n:::\n\n\nI will register 7 cores\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnum_clusters <- 7 #- 5 # 12 - 5\ndoParallel::registerDoParallel(num_clusters)\n\ncat('Registering', num_clusters, 'clusters for a parallel run\\n')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRegistering 7 clusters for a parallel run\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsystem.time({\n  outputMatrix <- foreach::foreach(i=1:nrow(myMatrix), .combine='rbind', .inorder=F) %dopar% {\n    out <- myMatrix[i, ] / i\n    return(out)\n  }\n})\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   user  system elapsed \n  0.041   0.059   0.052 \n```\n:::\n\n```{.r .cell-code}\n# stop the cluster\ndoParallel::stopImplicitCluster()\n```\n:::\n\n\n\nHere we see that lapply is much faster. Of course that is because of all the overheads and all that. \n\nNext, I will show to use the various `makeCluster()` options.",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}